{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TDibK0Yrxm_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week-6\n",
        "\n",
        "**Note:**:\n",
        "\n",
        "- For questions that involve plotting, just enter $0$ as the answer in the portal.\n",
        "\n"
      ],
      "metadata": {
        "id": "1TBHlt7hAdN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Run the cell given below to generate the data-matrix $X$ and target vector $y$. $X$ is of shape $(n, d)$, where $n$ denotes the number of samples and $d$ denotes the number of features. $y$ is of shape $(n,)$. You will be using this dataset for the rest of the assignment.\n",
        "\n",
        "**Do not edit this cell.**"
      ],
      "metadata": {
        "id": "XJKrscLo9qwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "X, y = load_diabetes(return_X_y = True)\n",
        "\n",
        "# set the random seed value to 0\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "GIygEzr49Xvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1\n",
        "How many samples are there in the dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "VAONMkaU91v7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "LnXmn5t-V8Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "samples = X.shape[0]\n",
        "print(samples)"
      ],
      "metadata": {
        "id": "U_WEAtwXDqVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe787e8-10e2-47b1-ef77-6ca287f53a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "\n",
        "How many features are there in the dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ozjMS6e_91y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "xvFvIHN9V_s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "features = X.shape[1]\n",
        "print(features)"
      ],
      "metadata": {
        "id": "ii_yZn4N-Di8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2935ce8-f82b-43a4-c1b3-b6793b17c7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3\n",
        "Write a function `shuffle_data(X, y)` that returns the shuffled $X$ and $y$.\n",
        "\n",
        "\n",
        "\n",
        "Note that it should shuffle the data pairs $(x_i, y_i)$.\n",
        "\n",
        "What will be the mean of the first 5 values in $y$?\n",
        "\n"
      ],
      "metadata": {
        "id": "HxIZaojUVGIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def shuffle_data(X, y):\n",
        "  X_shuffle , y_shuffle = shuffle(X , y , random_state = 0)\n",
        "  return X_shuffle , y_shuffle\n",
        "\n",
        "# Alternate Method\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "def shuffle_data(x,y):\n",
        "  # Set a random seed for reproducibility if needed\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # Generate a permutation of indices based on the length of y\n",
        "    permutation = np.random.permutation(len(y))\n",
        "\n",
        "    # Apply this permutation to both X and y\n",
        "    X_shuffled = X[permutation]\n",
        "    y_shuffled = y[permutation]\n",
        "\n",
        "    return X_shuffled, y_shuffled\n",
        "\n",
        "'''\n",
        "# First Shuffle the data\n",
        "X_shuffled , y_shuffled = shuffle_data(X , y)\n",
        "\n",
        "# Finding mean of the first 5 values in y\n",
        "mean_of_5_values_in_y = y_shuffled[:5].mean()\n",
        "print(\"the mean of the first 5 values in y is :\", mean_of_5_values_in_y)\n",
        "\n",
        "# Alternate Way\n",
        "'''\n",
        "print((y_shuffled[:5].sum()) / 5)\n",
        "'''"
      ],
      "metadata": {
        "id": "uLGsJyGkdgug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "cba90c60-a5cd-43b0-bb36-fd2024544503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean of the first 5 values in y is : 180.4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint((y_shuffled[:5].sum()) / 5)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SEED Function in Python**\n",
        "The Concept of np.random.seed()\n",
        "Imagine we have a deck of cards. Every time we shuffle it, the order of the cards changes. Now, what if we want to shuffle the deck in exactly the same way every time we start a game? That’s where the seed comes in. By setting a seed, we’re telling the random shuffling process to use a specific pattern.\n",
        "\n",
        "**Without a Seed:**\n",
        "\n",
        "**Generate random numbers without setting a seed**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "random_numbers = np.random.rand(5)\n",
        "\n",
        "print(random_numbers)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Each time we run this, we'll get different numbers.\n",
        "\n",
        "With a Seed:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generate random numbers with the seed set\n",
        "random_numbers = np.random.rand(5)\n",
        "print(random_numbers)\n",
        "\n",
        "```\n",
        "\n",
        "Every time we run this code, we'll get the same sequence of random numbers\n"
      ],
      "metadata": {
        "id": "KQHDX_RUQlAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 4\n",
        "\n",
        "Write a function `train_test_split(X, y, test_size)` that divides the data (X, y) into $X_{train}$, $X_{test}$, $y_{train}$, $y_{test}$ respectively as per test_size which should be a value between 0 and 1.\n",
        "\n",
        "That is, if test_size = $t$, then `int(t*n)` data points should go to test and the remaining data points should go to train.\n",
        "\n",
        "$X_{train}$, $X_{test}$, $y_{train}$, $y_{test}$ should be returned by the function.\n",
        "\n",
        "Set the test_size to be 0.25 and output the sum of all y values settling in $y_{test}$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pfsUsn_8WSXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "def train_test_split(X, y, test_size):\n",
        "\n",
        "  test_size = int((test_size) * samples)\n",
        "  train_size = samples - test_size\n",
        "  # print(train_size) --> for debugging purpose\n",
        "\n",
        "  X_train , X_test = X_shuffled[:train_size] , X_shuffled[train_size:]\n",
        "  y_train , y_test = y_shuffled[:train_size] , y_shuffled[train_size:]\n",
        "\n",
        "  return X_train , X_test , y_train , y_test\n",
        "\n",
        "# Calling the function\n",
        "X_train , X_test , y_train , y_test = train_test_split(X_shuffled , y_shuffled , test_size = 0.25)\n",
        "\n",
        "# Sum of all y_values setting in y_test\n",
        "print(\"Sum of all y_values setting in y_test is : \" , y_test.sum())\n",
        "\n",
        "# Alternate Method (Easy One)\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.25 ,  random_state = 0)\n",
        "\n",
        "and with this method there is no need to shuffle the data seperately as in this method ,\n",
        "it first shuffles the data and then selects randomly samples\n",
        "'''"
      ],
      "metadata": {
        "id": "Y5VZVbT8dg2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "18ddb8d8-f8a7-4081-83fe-3c0eed5d5749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of all y_values setting in y_test is :  16960.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.model_selection import train_test_split\\nX_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.25 ,  random_state = 0)\\n\\nand with this method there is no need to shuffle the data seperately as in this method ,\\nit first shuffles the data and then selects randomly samples\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 5\n",
        "\n",
        "What are the shapes of $X_{train}$, $X_{test}$, $y_{train}$, $y_{test}$ respectively?\n",
        "\n"
      ],
      "metadata": {
        "id": "D67g0r9ad8Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "shape_of_X_train = X_train.shape\n",
        "shape_of_X_test = X_test.shape\n",
        "shape_of_y_train = y_train.shape\n",
        "shape_of_y_test = y_test.shape\n",
        "\n",
        "print(\"shape_of_X_train :\" , shape_of_X_train)\n",
        "print(\"shape_of_X_test : \" , shape_of_X_test)\n",
        "print(\"shape_of_y_train :\" , shape_of_y_train)\n",
        "print(\"shape_of_y_test : \" , shape_of_y_test)"
      ],
      "metadata": {
        "id": "kTPAakKblF7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb2d9bb-4f4d-4aaf-e9b3-2c74fc2c3e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape_of_X_train : (332, 10)\n",
            "shape_of_X_test :  (110, 10)\n",
            "shape_of_y_train : (332,)\n",
            "shape_of_y_test :  (110,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 6\n",
        "Add a dummy feature, i.e., a column containing all 1's (as the first column) in $X_{train}$ and $X_{test}$.\n",
        "\n",
        "Take the transpose of both $X_{train}$ and $X_{test}$.\n",
        "\n",
        "What are the shapes of $X_{train}$ and $X_{test}$?\n",
        "\n"
      ],
      "metadata": {
        "id": "nYgSo6DLe0n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "X_train_with_ones = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
        "print(X_train_with_ones.shape)\n",
        "X_test_with_ones = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
        "# hstack() is Horizontal Stack\n",
        "\n",
        "# Taking Transpose\n",
        "X_train_transpose = X_train_with_ones.T\n",
        "X_test_transpose = X_test_with_ones.T\n",
        "\n",
        "# Printing the Shapes of X_train and X_test\n",
        "print(\"The Shape of X_train Transpose is : \" , X_train_transpose.shape)\n",
        "print(\"The Shape of X_test Transpose is : \" ,X_test_transpose.shape)"
      ],
      "metadata": {
        "id": "Lgv2V9qnnNv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefe1d61-1b62-43fa-ca53-f52fcbcdac63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(332, 11)\n",
            "The Shape of X_train Transpose is :  (11, 332)\n",
            "The Shape of X_test Transpose is :  (11, 110)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explaination of the Above Code**\n",
        "\n",
        "Adding a dummy feature (a column of ones) to a dataset is a common practice in linear regression and other linear models. This is typically done to incorporate the intercept term (also called the bias term) into the model.\n",
        "\n",
        "In a typical linear regression model, the goal is to fit a line (or a hyperplane in higher dimensions) that best represents the relationship between the input features 𝑋 and the output target 𝑦. The standard linear regression model is:\n",
        "\n",
        "$$\n",
        "y = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n\n",
        "$$\n",
        "\n",
        "$$\n",
        "where\n",
        "$$\n",
        "\n",
        "$$\n",
        "x_1, x_2, \\ldots, x_n \\quad \\text{are the feature inputs}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "w_1, w_2, \\ldots, w_n \\quad \\text{are the weights for each feature}\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "b \\text{ is the intercept or bias term.}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eng_zg65tZZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 7\n",
        "\n",
        "Write a function `compute_weights(X, y)` that uses the closed form formula of linear regression and returns a weight vector.\n",
        "\n",
        "Call this function by passing $X_{train}$ and $y_{train}$. As the dummy feature was added as the first column, the first value in the weight vector will be the intercept. What is its value (rounded to one decimal place)?\n",
        "\n"
      ],
      "metadata": {
        "id": "mYY6hNkYf7gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "def compute_weights(X, y):\n",
        "    # Step 1: Calculate X^T (transpose of X)\n",
        "    X_transpose = X.T\n",
        "\n",
        "    # Step 2: Calculate (X^T * X)\n",
        "    XX_transpose = X_transpose @ X\n",
        "\n",
        "    # Step 3: Calculate the inverse of (X^T * X)\n",
        "    XX_transpose_inverse = np.linalg.inv(XX_transpose)\n",
        "\n",
        "    # Step 4: Calculate (X^T * y)\n",
        "    X_y = X_transpose @ y\n",
        "\n",
        "    # Step 5: Calculate w = (X^T * X)^(-1) * X^T * y\n",
        "    w = XX_transpose_inverse @ X_y\n",
        "\n",
        "    return w\n",
        "\n",
        "# Assuming X_train_with_ones includes the bias (column of ones)\n",
        "weight_vector = compute_weights(X_train_with_ones, y_train)"
      ],
      "metadata": {
        "id": "XWxPR8N5nc17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weight_vector)\n",
        "print(weight_vector.shape)\n",
        "\n",
        "# Intercept (first value in the weight vector)\n",
        "intercept = round(weight_vector[0], 1)\n",
        "\n",
        "print(\"Intercept:\", intercept)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NoRJq5W3eEB",
        "outputId": "4066cd82-396e-4b19-d905-200bd22067f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 150.80818855  -37.55141005 -236.69770894  495.94156781  332.66085205\n",
            " -985.56901674  608.20547786  225.71676823  214.06133319  769.84183095\n",
            "  125.14414735]\n",
            "(11,)\n",
            "Intercept: 150.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **About the Weight Vector & Intercept Value**\n",
        "\n",
        "Formula used above is as follows:\n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        "\\mathbf{w} = (\\mathbf{X}^T \\mathbf{X})^{-1} (\\mathbf{X}^T \\mathbf{y})\n",
        "$$\n",
        "\n",
        "$$\n",
        "Where\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{w}:\\text{is the weight vector}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{X}:\\text{is the input matrix (with dummy column of 1s)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{y}:\\text{is the label vector}\n",
        "$$\n",
        "\n",
        "To find the intercept value in the weight vector, we need to implement the compute_weights function using the closed-form solution for linear regression\n",
        "\n",
        "\n",
        "The intercept is the first value in the weight vector because we added a column of ones as the first column in our feature matrix. This allows the linear regression model to include the intercept term naturally during the weight calculation process."
      ],
      "metadata": {
        "id": "OvS1DFWECSgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 8\n",
        "\n",
        "Write a function `MSE(X, y, w)` that returns the mean squared error for the given `X`, `y` as per `w` values.\n",
        "\n",
        "Using this function, compute the train error and test error.\n",
        "\n",
        "Note: Here `y` is the true `y` for `X`.\n",
        "\n",
        "Compute both train and test error.\n",
        "\n",
        "What is the value of test error?\n"
      ],
      "metadata": {
        "id": "XUKviVRZoh2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "def MSE(X , y , w):\n",
        "  Xw = X @ w\n",
        "  diff = (Xw - y)\n",
        "  Mean_Squared_Error = np.mean(diff ** 2)\n",
        "  return Mean_Squared_Error\n",
        "\n",
        "Train_Error = MSE(X_train_with_ones , y_train , weight_vector)\n",
        "Test_Error = MSE(X_test_with_ones , y_test , weight_vector)\n",
        "\n",
        "print(\"Train Error is : \" , Train_Error)\n",
        "print(\"Test Error is : \" ,Test_Error)"
      ],
      "metadata": {
        "id": "PkAULslJD48q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078bc55d-10c7-4640-dd49-1ec14652daa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error is :  2921.8874514067493\n",
            "Test Error is :  2745.430111174355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 9\n",
        "\n",
        "Write a function `compute_weights_ridge(X, y)` that uses the closed form formula of Ridge regression and returns a weight vector.\n",
        "\n",
        "Call this function by passing  `X_train`, `y_train` and 0.3 as the value of regularization strength.\n",
        "\n",
        "\n",
        "Find the sum of values in the weight vector obtained. How much reduction in total sum of weights is achieved with respect to the the weight vector obtained from 'plain' linear regression (without regularization) computed earlier.\n"
      ],
      "metadata": {
        "id": "mZZVbejulHyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "def compute_weights_ridge(X , y, R):\n",
        "\n",
        "  X_transpose_X = X.T @ X\n",
        "  # Since X_transpose_X is a Square Matrix we can easily create\n",
        "  # a corresponding Identity matrix of same shape\n",
        "\n",
        "  Identity_Matrix = np.eye(X_transpose_X.shape[0], X_transpose_X.shape[1])\n",
        "  Regularizer_Identity_matrix = R * Identity_Matrix\n",
        "\n",
        "  # Adding the matrices\n",
        "  m = X_transpose_X + Regularizer_Identity_matrix\n",
        "\n",
        "  # Taking the Inverse if the matrix m\n",
        "  m_inverse = np.linalg.inv(m) # -----------> 1\n",
        "\n",
        "  # Computing the Product of X^T y\n",
        "  m1 = X.T @ y # ---------------------------> 2\n",
        "\n",
        "  # Mulitplying 1 & 2\n",
        "  w = m_inverse @ m1\n",
        "\n",
        "  # Returning the final Weight Vector\n",
        "  return w\n",
        "\n",
        "# Calling the Function and storing the result in a variable\n",
        "weight_vector_Ridge = compute_weights_ridge(X_train_with_ones , y_train , 0.3)\n",
        "print(weight_vector_Ridge)"
      ],
      "metadata": {
        "id": "LCyCWK9dqZm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e15f6c-0d47-4427-d114-55c1212a1365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 151.06379834    1.22192839 -142.74026577  386.0768882   269.1193914\n",
            "  -30.20155721  -71.07733651 -151.21600325  105.59399288  329.16542194\n",
            "  135.52074802]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sum of values in the weight vector obtained.\n",
        "# How much reduction in total sum of weights is achieved with respect to the the weight\n",
        "# vector obtained from 'plain' linear regression (without regularization) computed earlier.\n",
        "\n",
        "w_sum_ridge = weight_vector_Ridge.sum()\n",
        "w_sum_standard = weight_vector.sum()\n",
        "\n",
        "print(\"The Sum of Values in the weight vector obtained under Ridge Regression is : \" , w_sum_ridge)\n",
        "print(\"\\n\")\n",
        "print(\"Reduction in total sum of weights is achieved with respect to the weight vector\" + \"\\n\" +\n",
        "      \"vector obtained from 'plain' linear regression (without regularization) computed earlier is : \" , w_sum_standard - w_sum_ridge)"
      ],
      "metadata": {
        "id": "f7VL3ZLosCtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2ca715-a860-46c1-9cb8-bab5171564c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Sum of Values in the weight vector obtained under Ridge Regression is :  982.5270064293238\n",
            "\n",
            "\n",
            "Reduction in total sum of weights is achieved with respect to the weight vector\n",
            "vector obtained from 'plain' linear regression (without regularization) computed earlier is :  680.0350238507224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of X_train_transpose @ X_train_with_ones\n",
        "# for debugging purpose\n",
        "M = X_train_transpose @ X_train_with_ones\n",
        "print(M.shape)"
      ],
      "metadata": {
        "id": "l9f4nxNHk_sx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f23057-9cf6-45a9-d2d9-79d87aa4f728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Formula Used For Computing The Weight Vector in Ridge Regression**\n",
        "\n",
        "\n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{w}}_R = (\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I})^{-1} (\\mathbf{X}^T \\mathbf{y})\n",
        "$$\n",
        "\n",
        "$$ where $$\n",
        "$$ \\mathbf{X}:  \\textbf{is the feature Matrix}. $$\n",
        "$$ \\lambda: \\text{is the Regularization Parameter} $$\n",
        "$$ \\mathbf{I}:  \\textbf{is the Identity Matrix}. $$"
      ],
      "metadata": {
        "id": "vgEw1akT8A6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ways to Create Identity Matrix**"
      ],
      "metadata": {
        "id": "DJh5sbhauvvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = np.identity(3)\n",
        "print(id)"
      ],
      "metadata": {
        "id": "a963dcOAji1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba36befa-0721-4e31-d120-9013cdbd91a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternate way to Create An Indentity Matrix\n",
        "id1 = np.eye(3)\n",
        "print(id1)\n",
        "'''\n",
        "The np.eye() function is more flexible. It allows us to create a square identity\n",
        "matrix or a rectangular matrix with ones on the diagonal and zeros elsewhere.\n",
        "'''"
      ],
      "metadata": {
        "id": "KoJkyFaFjro3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "80e35252-2450-4253-e8cf-e8fdc3845543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe np.eye() function is more flexible. It allows us to create a square identity\\nmatrix or a rectangular matrix with ones on the diagonal and zeros elsewhere.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also create a rectangular matrix using np.eye()\n",
        "# by specifying the number of rows and columns:\n",
        "\n",
        "id3 = np.eye(M.shape[0], M.shape[1])\n",
        "print(id3)"
      ],
      "metadata": {
        "id": "EgKySjmhkVq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bcf75b-db73-4ca5-82d2-f99c9f0b70b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 10\n",
        "\n",
        "Compute the train error and test error. What is their absolute difference?\n",
        "\n"
      ],
      "metadata": {
        "id": "LC9Au6sPt1oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "\n",
        "# Calling the MSE() Function defined earlier\n",
        "Train_Error_Ridge = MSE(X_train_with_ones , y_train , weight_vector_Ridge)\n",
        "Test_Error_Ridge = MSE(X_test_with_ones , y_test , weight_vector_Ridge)\n",
        "\n",
        "print(\"Train Error under Ridge Regression is : \" , Train_Error_Ridge)\n",
        "print(\"Test Error under Ridge Regression is : \" ,Test_Error_Ridge)\n",
        "print(\"The Absolute Difference Between Train_Error & Test Error under Ridge Regression is :\" , abs(Test_Error_Ridge - Train_Error_Ridge))"
      ],
      "metadata": {
        "id": "iOUjJJpZ3BaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715eb912-7d20-4b4f-cc00-3bbdb6f605f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error under Ridge Regression is :  3058.8016386551403\n",
            "Test Error under Ridge Regression is :  2959.3318999461417\n",
            "The Absolute Difference Between Train_Error & Test Error under Ridge Regression is : 99.46973870899865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 11\n",
        "\n",
        "Use 10 different values between 0 and 5 as the regularization strength and keep a record of the weight vectors obtained for each. Further, calculate the sum of weights for each weight vector.\n",
        "\n",
        "Plot these sums of weights (on y-axis) with respect to the regularization strength (on x-axis) and observe the reduction in (sum of) weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wn6-FG5puh8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your solution code here\n",
        "\n",
        "# Computing and Storing different values\n",
        "# for lambda and computing the corresponding sum\n",
        "# of weight vector at that lambda (or regularizer)\n",
        "# and then storing this info in a dictionary\n",
        "# where keys are values of regularizer\n",
        "# and values are weight vectoe sums values\n",
        "\n",
        "import random\n",
        "diff_regularizer_values_weights = {}\n",
        "random.seed(0)\n",
        "\n",
        "for _ in range(10):\n",
        "  value = round(random.uniform(0 , 5) , 2)\n",
        "  value_w = (compute_weights_ridge(X_train_with_ones , y_train , value)).sum()\n",
        "  diff_regularizer_values_weights[value] = round(value_w , 2)\n",
        "\n",
        "print(diff_regularizer_values_weights)"
      ],
      "metadata": {
        "id": "zlzueWYWwtSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0d6a67-4413-4c67-ac5d-5513b2ad5e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{4.22: 551.15, 3.79: 576.42, 2.1: 714.51, 1.29: 814.89, 2.56: 669.16, 2.02: 723.16, 3.92: 568.46, 1.52: 783.3, 2.38: 686.06, 2.92: 638.25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(diff_regularizer_values_weights.keys() , diff_regularizer_values_weights.values() , color = \"black\")\n",
        "plt.xlabel(\"Regularizer Values (or $\\\\lambda$)\")\n",
        "plt.ylabel(\"Sum of Weight Vectors\")\n",
        "plt.title(\"Sum of Weight Vectors V/S Regularizer Values (or $\\\\lambda$)\")\n",
        "# plt.legend()"
      ],
      "metadata": {
        "id": "e6puPtnq47m7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "c125a35d-7f2a-4763-d637-9c29ac3f7bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Sum of Weight Vectors V/S Regularizer Values (or $\\\\lambda$)')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computing R Square Value (R^2)**\n",
        "\n"
      ],
      "metadata": {
        "id": "lWPUKRFvAwZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Function For Residual Sum Squared\n",
        "def RSS(X , y , w):\n",
        "  Xw = X @ w\n",
        "  diff = Xw - y\n",
        "  Residual_Sum_Sq = (diff ** 2).sum()\n",
        "\n",
        "  return Residual_Sum_Sq\n",
        "\n",
        "Standard_Linear_RSS = RSS(X_test_with_ones , y_test , weight_vector)\n",
        "Ridge_Regression_RSS = RSS(X_test_with_ones , y_test , weight_vector_Ridge)\n",
        "\n",
        "print(\"The Residual Sum Squared for Standard Linear Regression Algorithm is : \", Standard_Linear_RSS)\n",
        "print(\"The Residual Sum Squared for Ridge Linear Regression Algorithm is : \", Ridge_Regression_RSS)\n",
        "print(\"_____________________________________________________________________________________________\")\n",
        "\n",
        "# __________________________________________________________________________________________________________\n",
        "\n",
        "# Creating the Function For Total Sum Squared\n",
        "def TSS(y):\n",
        "  avg_y = np.average(y)\n",
        "  Total_Sum_Sq = ((y - avg_y) ** 2).sum()\n",
        "\n",
        "  return Total_Sum_Sq\n",
        "\n",
        "Common_TSS = TSS(y_test)\n",
        "print(\"The Total Sum Squared for Both the Algorithms is : \" , Common_TSS)"
      ],
      "metadata": {
        "id": "4rdbi37ZA6dR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3a076a-c0ea-4c9c-8509-d0fe34b8fde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Residual Sum Squared for Standard Linear Regression Algorithm is :  301997.312229179\n",
            "The Residual Sum Squared for Ridge Linear Regression Algorithm is :  325526.5089940756\n",
            "_____________________________________________________________________________________________\n",
            "The Total Sum Squared for Both the Algorithms is :  736044.3636363635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unexplained_variance_standard = round((Standard_Linear_RSS / Common_TSS) , 2)\n",
        "explained_variance_standard = 1 - unexplained_variance_standard\n",
        "\n",
        "print(\"The R^2 Square for Standard Linear Algorithm is : \" , round(explained_variance_standard , 2))"
      ],
      "metadata": {
        "id": "xF2M18kTHg3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a936ae3-9238-446e-938c-2640a9a5acef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The R^2 Square for Standard Linear Algorithm is :  0.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unexplained_variance_ridge = round((Ridge_Regression_RSS / Common_TSS) , 2)\n",
        "explained_variance_ridge = 1 - unexplained_variance_ridge\n",
        "\n",
        "print(\"The R^2 Square for Ridge_Regression Algorithm is : \" , round(explained_variance_ridge , 2))"
      ],
      "metadata": {
        "id": "-SCKntwjLV9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d03918b-7835-49a5-f39e-f9276c54c2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The R^2 Square for Ridge_Regression Algorithm is :  0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **R^2 Square Evaluation Metric Explaination**\n",
        "\n",
        "$$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "$$ {\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} : RSS$$\n",
        "$$ {\\sum_{i=1}^{n} (y_i - \\bar{y})^2} : TSS$$\n",
        "\n",
        "$$ where $$\n",
        "$$ \\text{RSS} : \\text{Residual Sum of Squares} $$\n",
        "$$ \\text{TSS} : \\text{Total Sum of Squares} $$\n",
        "\n",
        "**Definition**\n",
        "\n",
        "The R-squared (or coefficient of determination) measures the proportion of the variance in the dependent variable\n",
        "𝑦\n",
        " that is predictable from the independent variables\n",
        "𝑋\n",
        ".\n",
        "\n",
        "**RSS**\n",
        "\n",
        "This is the sum of the squared differences between the actual values 𝒚i and the predicted values ̂{y}_i . It measures how much error remains in the model's predictions.\n",
        "\n",
        "\n",
        "**TSS**\n",
        "\n",
        "This measures the total variation in the data, i.e., how much the actual values\n",
        "𝒚i deviate from the mean of the data y avg . It's the total variability in\n",
        "𝑦\n",
        "that we are trying to explain with our model.\n",
        "\n",
        "\n",
        "\n",
        "**Intuition of R^2**\n",
        "\n",
        "It tells us how much of the total variation in\n",
        "𝑦\n",
        "is explained by the model.\n",
        "\n",
        "\n",
        "\n",
        "*   When R^2 = 1 : All the points lie perfectly on the regression line, meaning 100% of the variation in\n",
        "𝑦\n",
        "is explained by\n",
        "𝑋\n",
        "\n",
        "*   When R^2 = 0 : The model does no better than simply predicting the mean of\n",
        "𝑦 for every point (no explanatory power).\n",
        "\n"
      ],
      "metadata": {
        "id": "zFSNila7Z0-2"
      }
    }
  ]
}